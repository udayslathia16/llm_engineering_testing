{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97922aba-106d-43a5-9287-162d0fb63cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d114440-e755-4790-b836-ae3bf0fcd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key (replace with your actual key or set as environment variable)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3640e1d-8f07-48e2-bcbb-e552aad69a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"your-api-key-here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4302258f-9df5-49b3-8602-7bfc385b6ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebsiteCrawler:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        self.scrape()\n",
    "    \n",
    "    def scrape(self):\n",
    "        try:\n",
    "            print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] Starting scrape process...\")\n",
    "            \n",
    "            # EDIT 1: Add progress bar for Chrome setup\n",
    "            setup_steps = [\"Configuring Chrome\", \"Setting up driver\", \"Initializing browser\"]\n",
    "            for step in tqdm(setup_steps, desc=\"üîß Browser Setup\", unit=\"step\"):\n",
    "                time.sleep(0.5)  # Simulate setup time\n",
    "                \n",
    "            # Chrome options\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_options.add_argument(\"--disable-gpu\")\n",
    "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "            chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "            \n",
    "            # Use ChromeDriverManager to automatically download and manage ChromeDriver\n",
    "            service = Service(ChromeDriverManager().install())\n",
    "            \n",
    "            # Create driver with service\n",
    "            driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "            driver.set_page_load_timeout(30)\n",
    "            \n",
    "            print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] üîç Loading: {self.url}\")\n",
    "            driver.get(self.url)\n",
    "            \n",
    "            # EDIT 2: Add progress bar for page loading\n",
    "            loading_steps = range(10)  # Simulate 10 loading steps\n",
    "            for _ in tqdm(loading_steps, desc=\"üì• Loading Page\", unit=\"step\"):\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            # Try to wait for main content\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"main\"))\n",
    "                )\n",
    "            except Exception:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass  # Continue anyway\n",
    "            \n",
    "            # Get title and page source\n",
    "            self.title = driver.title\n",
    "            page_source = driver.page_source\n",
    "            driver.quit()\n",
    "            \n",
    "            print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚úÖ Page loaded: {self.title}\")\n",
    "            \n",
    "            # EDIT 3: Add progress bar for content parsing\n",
    "            parsing_steps = [\"Parsing HTML\", \"Removing unwanted elements\", \"Extracting text\", \"Cleaning content\"]\n",
    "            for step in tqdm(parsing_steps, desc=\"üîç Processing Content\", unit=\"step\"):\n",
    "                time.sleep(0.3)\n",
    "                \n",
    "            # Parse with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            # Remove unwanted elements\n",
    "            for element in soup([\"script\", \"style\", \"img\", \"input\", \"button\", \"nav\", \"footer\", \"header\"]):\n",
    "                element.decompose()\n",
    "            \n",
    "            # Get main content\n",
    "            main = soup.find('main') or soup.find('article') or soup.find('.content') or soup.find('body')\n",
    "            if main:\n",
    "                self.text = main.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "            \n",
    "            # Clean up text\n",
    "            lines = [line.strip() for line in self.text.split('\\n') if line.strip() and len(line.strip()) > 2]\n",
    "            self.text = '\\n'.join(lines[:200])  # Limit to first 200 lines\n",
    "            \n",
    "            print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] üìÑ Extracted {len(self.text)} characters\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå Error occurred: {e}\")\n",
    "            self.title = \"Error occurred\"\n",
    "            self.text = \"Could not scrape website content\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16a75d82-aeea-4855-bde7-41e6cdfe5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7001315a-d3be-4dae-9ed4-e49bf74e9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ede9bc69-f949-41a8-945e-82e768848ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff0b659b-f835-4197-935b-9ac1329465f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_gpt(url):\n",
    "    \"\"\"Scrape website and summarize with GPT\"\"\"\n",
    "    print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] üöÄ Starting website analysis for: {url}\")\n",
    "    \n",
    "    site = WebsiteCrawler(url)\n",
    "    if \"Error occurred\" in site.title or len(site.text) < 50:\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå Failed to scrape meaningful content from {url}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ü§ñ Creating summary...\")\n",
    "    \n",
    "    try:\n",
    "        # Debug: Print text length and first 500 characters\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] üìä Text length: {len(site.text)} characters\")\n",
    "        print(f\"üìù First 500 characters: {site.text[:500]}...\")\n",
    "        \n",
    "        # Check if OpenAI API key is set\n",
    "        if not openai.api_key:\n",
    "            print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå OpenAI API key not set. Please set your API key.\")\n",
    "            return\n",
    "        \n",
    "        # EDIT 4: Add progress bar for API call\n",
    "        api_steps = [\"Preparing request\", \"Sending to OpenAI\", \"Processing response\", \"Formatting output\"]\n",
    "        for step in tqdm(api_steps, desc=\"ü§ñ AI Processing\", unit=\"step\"):\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # Create summary with timeout and error handling\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] üîÑ Calling OpenAI API...\")\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # You'll need to define MODEL_OPENAI or use this default\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt_for(site)}\n",
    "            ],\n",
    "            max_tokens=500,  # Limit response length\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚úÖ Got response from OpenAI\")\n",
    "        web_summary = response.choices[0].message.content\n",
    "        \n",
    "        print(f\"\\nüïê [{datetime.datetime.now().strftime('%H:%M:%S')}] \" + \"=\"*50)\n",
    "        print(\"üìã WEBSITE SUMMARY:\")\n",
    "        print(\"=\"*50)\n",
    "        print(web_summary)\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Also display as markdown if in Jupyter\n",
    "        try:\n",
    "            display(Markdown(web_summary))\n",
    "        except NameError:\n",
    "            # If not in Jupyter, just print\n",
    "            pass\n",
    "            \n",
    "    except openai.RateLimitError:\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå OpenAI API rate limit exceeded. Please wait and try again.\")\n",
    "    except openai.AuthenticationError:\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå OpenAI API authentication failed. Please check your API key.\")\n",
    "    except openai.APIConnectionError:\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå Failed to connect to OpenAI API. Please check your internet connection.\")\n",
    "    except Exception as e:\n",
    "        print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] ‚ùå Error calling OpenAI API: {e}\")\n",
    "        print(f\"üìÑ Scraped content preview: {site.text[:200]}...\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f96ebed0-bcc0-4ab9-bb95-102b9fd41f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïê [18:15:12] üéØ Starting website analysis...\n",
      "üïê [18:15:12] üöÄ Starting website analysis for: https://openai.com\n",
      "üïê [18:15:12] Starting scrape process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîß Browser Setup: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.98step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïê [18:15:18] üîç Loading: https://openai.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì• Loading Page: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.99step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïê [18:15:32] ‚úÖ Page loaded: OpenAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Processing Content: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.32step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïê [18:15:33] üìÑ Extracted 3329 characters\n",
      "üïê [18:15:37] ü§ñ Creating summary...\n",
      "üïê [18:15:37] üìä Text length: 3329 characters\n",
      "üìù First 500 characters: OpenAI\n",
      "What can I help with?\n",
      "Message ChatGPT\n",
      "Quiz me on vocabulary\n",
      "Plan a surf trip to Costa Rica in August\n",
      "India stock market today\n",
      "Explica por qu√© el ma√≠z palomitas explota\n",
      "Teach me Mahjong for beginners\n",
      "Find hiking boots for wide feet\n",
      "Explain this code\n",
      "Was mach ich in Berlin wenn es regnet?\n",
      "What are some outdoor markets in Mexico City?\n",
      "R√©digez une note de remerciement\n",
      "Recommend an easy potluck dish\n",
      "„Éè„Éº„Éï„Éû„É©„ÇΩ„É≥„ÅÆ„Éà„É¨„Éº„Éã„É≥„Ç∞„ÇíÊâã‰ºù„Å£„Å¶„Åè„Å†„Åï„ÅÑ\n",
      "Help me improve this job description\n",
      "Write a Python script\n",
      "Draw a pictu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ü§ñ AI Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.99step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïê [18:15:39] üîÑ Calling OpenAI API...\n",
      "üïê [18:15:41] ‚úÖ Got response from OpenAI\n",
      "\n",
      "üïê [18:15:41] ==================================================\n",
      "üìã WEBSITE SUMMARY:\n",
      "==================================================\n",
      "# Summary\n",
      "The website is for OpenAI, a company that provides various AI services and products. The site includes features like ChatGPT for interacting with AI, vocabulary quizzes, travel planning assistance, coding help, and more. There are also sections for news, releases, stories, and research related to GPT-5, the latest model. The company focuses on AI advancements and their applications across different domains, including business and healthcare. Recent updates include the introduction of GPT-5, safety evaluations, and partnerships with companies like Oracle.\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Summary\n",
       "The website is for OpenAI, a company that provides various AI services and products. The site includes features like ChatGPT for interacting with AI, vocabulary quizzes, travel planning assistance, coding help, and more. There are also sections for news, releases, stories, and research related to GPT-5, the latest model. The company focuses on AI advancements and their applications across different domains, including business and healthcare. Recent updates include the introduction of GPT-5, safety evaluations, and partnerships with companies like Oracle."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the function\n",
    "print(f\"üïê [{datetime.datetime.now().strftime('%H:%M:%S')}] üéØ Starting website analysis...\")\n",
    "summarize_gpt('https://openai.com')\n",
    "# summarize_gpt('https://stripe.com')\n",
    "# summarize_gpt('https://vercel.com')\n",
    "# summarize_gpt('https://react.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
